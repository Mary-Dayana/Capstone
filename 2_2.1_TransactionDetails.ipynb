{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize  Spark Session\n",
    "spark = SparkSession.builder.appName(\"Customer\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from Database into Spark DataFrame's for Branch, Credit and Customer\n",
    "\n",
    "df_credit = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "    .option(\"dbtable\", \"CDW_SAPP_CREDIT_CARD\") \\\n",
    "    .option(\"user\", \"root\") \\\n",
    "    .option(\"password\", \"password\") \\\n",
    "    .load()\n",
    "\n",
    "df_customer = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "    .option(\"dbtable\", \"CDW_SAPP_CUSTOMER\") \\\n",
    "    .option(\"user\", \"root\") \\\n",
    "    .option(\"password\", \"password\") \\\n",
    "    .load()  \n",
    "\n",
    "df_branch = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "    .option(\"dbtable\", \"CDW_SAPP_BRANCH\") \\\n",
    "    .option(\"user\", \"root\") \\\n",
    "    .option(\"password\", \"password\") \\\n",
    "    .load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display both CreditCard and Customer Dataframes\n",
    "\n",
    "df_credit.show(1)\n",
    "df_customer.show(1)\n",
    "df_branch.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join two dataframes and select required fields\n",
    "\n",
    "df_join = df_credit.join(df_customer, df_credit.CUST_SSN == df_customer.SSN, 'inner').select(col('SSN'), col('CUST_ZIP'), col('TIMEID'), \\\n",
    "          col('TRANSACTION_ID'), col('TRANSACTION_VALUE'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+--------------+-----------------+\n",
      "|      SSN|CUST_ZIP|  TIMEID|TRANSACTION_ID|TRANSACTION_VALUE|\n",
      "+---------+--------+--------+--------------+-----------------+\n",
      "|123455659|   10954|20180723|         22772|            97.57|\n",
      "+---------+--------+--------+--------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the joined Dataframe to verify the required fields\n",
    "\n",
    "df_join.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view for the join DataFrame\n",
    "\n",
    "df_join.createOrReplaceTempView('CC_CUST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+--------------+-----------------+\n",
      "|      SSN|CUST_ZIP|  TIMEID|TRANSACTION_ID|TRANSACTION_VALUE|\n",
      "+---------+--------+--------+--------------+-----------------+\n",
      "|123451357|   53066|20180606|         44947|            18.13|\n",
      "|123451357|   53066|20180611|         44915|            86.64|\n",
      "|123451357|   53066|20180610|         44900|            88.73|\n",
      "|123451357|   53066|20180626|         44896|            13.47|\n",
      "|123451357|   53066|20180617|         44868|            26.73|\n",
      "+---------+--------+--------+--------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query ---values in input---  53066   2018   06\n",
    "\n",
    "# data = spark.sql('select * from CC_CUST where CUST_ZIP == \"53066\" and substr(TIMEID,1,4) == \"2018\" and substr(TIMEID,5,2)==\"06\"')\n",
    "# data.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Functional Requirements - Application Front-End\n",
    "\n",
    "    2.1 Transaction Details Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside the function 53066 2018 06\n",
      "+---------+--------+--------+--------------+-----------------+\n",
      "|      SSN|CUST_ZIP|  TIMEID|TRANSACTION_ID|TRANSACTION_VALUE|\n",
      "+---------+--------+--------+--------------+-----------------+\n",
      "|123457562|   53066|20180628|         12436|            65.84|\n",
      "|123458614|   53066|20180628|          6691|             19.2|\n",
      "|123457286|   53066|20180627|         13783|            42.01|\n",
      "|123451357|   53066|20180626|         44896|            13.47|\n",
      "|123458614|   53066|20180625|          6697|             6.66|\n",
      "+---------+--------+--------+--------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Used to display the transactions made by customers living in a given zip code for a given month and year. \n",
    "# Order by day in descending order.\n",
    "\n",
    "# Function \n",
    "def trans_value(Zip,Year,Month):\n",
    "    print(\"inside the function\", Zip, Year, Month)\n",
    "    data = spark.sql('select distinct * from CC_CUST where CUST_ZIP == \"{}\" and substr(TIMEID,1,4) == \"{}\" \\\n",
    "        and substr(TIMEID,5,2) == \"{}\" ORDER BY substr(TIMEID,7,2) DESC'.format(Zip,Year,Month))\n",
    "    data.show(5)\n",
    "\n",
    "\n",
    "Zip = str(input(\"Please Enter zipcode in the cell: \"))\n",
    "Year = str(input(\"Please Enter year in the cell: \"))\n",
    "Month = str(input(\"Please Enter month in the cell: \"))\n",
    "trans_value(Zip,Year,Month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------------+----------------------+\n",
      "|transaction_type|count(transaction_type)|sum(transaction_value)|\n",
      "+----------------+-----------------------+----------------------+\n",
      "|       Education|                   6638|     337980.0700000016|\n",
      "|   Entertainment|                   6635|    338950.09999999945|\n",
      "|      Healthcare|                   6723|    340476.19999999896|\n",
      "|         Grocery|                   6549|     337051.6299999997|\n",
      "|            Test|                   6683|     341310.3700000002|\n",
      "|             Gas|                   6605|    336059.26000000036|\n",
      "|           Bills|                   6861|     351405.2800000001|\n",
      "+----------------+-----------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Used to display the number and total values of transactions for a given type.\n",
    "\n",
    "# Query for displaying transaction count for each transaction type and Total of Transaction value for each Transaction type\n",
    "\n",
    "df_credit.select('transaction_type','transaction_value').groupby('transaction_type').agg(count('transaction_type'), \\\n",
    "      sum('transaction_value')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view for Credit Card\n",
    "\n",
    "df_credit.createOrReplaceTempView('cdw_cc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+---------+\n",
      "|transaction_type|trans_count|trans_val|\n",
      "+----------------+-----------+---------+\n",
      "|       Education|       6638|337980.07|\n",
      "|   Entertainment|       6635| 338950.1|\n",
      "|      Healthcare|       6723| 340476.2|\n",
      "|         Grocery|       6549|337051.63|\n",
      "|            Test|       6683|341310.37|\n",
      "|             Gas|       6605|336059.26|\n",
      "|           Bills|       6861|351405.28|\n",
      "+----------------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute the query in the Spark DataFrame \n",
    "\n",
    "result = spark.sql('SELECT transaction_type, COUNT(*) as trans_count, \\\n",
    "                round(SUM(transaction_value),2) as trans_val \\\n",
    "                FROM cdw_cc \\\n",
    "                GROUP BY transaction_type')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+-----------------+\n",
      "|Branch_code| branch_name|branch_state|transaction_value|\n",
      "+-----------+------------+------------+-----------------+\n",
      "|         26|Example Bank|          TX|            56.12|\n",
      "|         29|Example Bank|          CA|            17.03|\n",
      "|         29|Example Bank|          CA|            86.18|\n",
      "|         26|Example Bank|          TX|            25.01|\n",
      "|         29|Example Bank|          CA|            66.37|\n",
      "+-----------+------------+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Used to display the total number and total values of transactions for branches in a given state.\n",
    "\n",
    "df_join_brcc = df_credit.join(df_branch, df_branch.BRANCH_CODE == df_credit.BRANCH_CODE, 'inner')\\\n",
    "          .select(df_branch['branch_code'].alias('Branch_code'), \\\n",
    "          col('branch_name'), col('branch_state'), col('transaction_value'))\n",
    "df_join_brcc.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view fro the joined Dataframe\n",
    "\n",
    "df_join_brcc.createOrReplaceTempView('data_br_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-----------------+\n",
      "|branch_code|Count|Total_transaction|\n",
      "+-----------+-----+-----------------+\n",
      "|         26|  408|         20156.75|\n",
      "|         43|  414|         20605.86|\n",
      "|         52|  378|         18923.41|\n",
      "|         56|  398|         20544.27|\n",
      "|        173|  431|         21234.44|\n",
      "+-----------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Function\n",
    "\n",
    "def trans_by_branch(state):\n",
    "    result_state = spark.sql(\"SELECT branch_code, COUNT(branch_code) as Count, \\\n",
    "                round(SUM(transaction_value),2) as Total_transaction\\\n",
    "                FROM data_br_view \\\n",
    "                WHERE BRANCH_STATE == '{}' \\\n",
    "                GROUP BY branch_code \\\n",
    "                ORDER BY branch_code\".format(state))\n",
    "    result_state.show()\n",
    "\n",
    "state = str(input(\"Enter State : \"))\n",
    "trans_by_branch(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7362ee329c755442e6ea87193ce457cddc1074042b9236f0fcace940202c9aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
